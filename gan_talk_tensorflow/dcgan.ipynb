{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhangxiaojie/anaconda3/envs/nlpv3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import glob\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.platform import flags\n",
    "import argparse\n",
    "tf.app.flags.FLAGS = flags._FlagValues()\n",
    "tf.app.flags._global_parser = argparse.ArgumentParser()\n",
    "tf.app.flags.DEFINE_integer(flag_name=\"epochs\", docstring=\"number of training epoches\", default_value=10)\n",
    "tf.app.flags.DEFINE_integer(flag_name=\"crop_height\", docstring=\"image cropping height\", default_value=500)\n",
    "tf.app.flags.DEFINE_integer(flag_name=\"crop_width\", docstring=\"image cropping width\", default_value=500)\n",
    "tf.app.flags.DEFINE_integer(flag_name=\"target_height\", docstring=\"image resize height\", default_value=64)\n",
    "tf.app.flags.DEFINE_integer(flag_name=\"target_width\", docstring=\"image resize width\", default_value=64)\n",
    "tf.app.flags.DEFINE_integer(flag_name=\"batch_size\", docstring=\"image batchsize\", default_value=128)\n",
    "tf.app.flags.DEFINE_float(flag_name=\"learning_rate\", docstring=\"learning rate\", default_value=1e-3)\n",
    "tf.app.flags.DEFINE_boolean(flag_name=\"is_training\", docstring=\"whether the model is at training stage\", default_value=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataProcess(object):\n",
    "    def __init__(self, src_dir):\n",
    "        self.src_dir = src_dir\n",
    "        self._process()\n",
    "    def _process(self):\n",
    "        # Following code is according to:\n",
    "        # https://stackoverflow.com/questions/33849617/how-do-i-convert-a-directory-of-jpeg-images-to-tfrecords-file-in-tensorflow\n",
    "        input_files = tf.train.string_input_producer(glob.glob(os.path.join(self.src_dir,\"*\")), num_epochs = tf.app.flags.FLAGS.epochs)\n",
    "        reader = tf.WholeFileReader()\n",
    "        key, value = reader.read(input_files)\n",
    "        self.labels = key\n",
    "        self.imgs = tf.random_crop(tf.image.decode_jpeg(value), (tf.app.flags.FLAGS.crop_height, tf.app.flags.FLAGS.crop_width, 3))\n",
    "        min_after_dequeue = 1000\n",
    "        capacity = min_after_dequeue + 3 * tf.app.flags.FLAGS.batch_size\n",
    "        self.label_batch, self.img_batch = tf.train.shuffle_batch([self.labels, self.imgs], \\\n",
    "                    batch_size=tf.app.flags.FLAGS.batch_size, capacity=capacity, min_after_dequeue=min_after_dequeue)\n",
    "        # Resize The image to target size\n",
    "        self.img_batch = tf.image.resize_area(self.img_batch, (tf.app.flags.FLAGS.target_height, tf.app.flags.FLAGS.target_width))\n",
    "        \n",
    "    def get_data(self):\n",
    "        return self.label_batch, self.img_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp = DataProcess(\"../dataset/102flowers/jpg/\")\n",
    "dp._process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmEP4g+9wzCH8wXc45hD/HzNQfTIN3rLDAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1254998630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with tf.Session() as s:\n",
    "    s.run(tf.global_variables_initializer())\n",
    "    s.run(tf.local_variables_initializer())\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(coord=coord)\n",
    "    try:\n",
    "        while True:\n",
    "            labels, imgs = s.run(dp.get_data(), feed_dict = {})\n",
    "            #print(np.min(imgs))\n",
    "            plt.imshow(imgs[0,:,:,:]/256.0)\n",
    "            plt.show()\n",
    "            break\n",
    "    except tf.errors.OutOfRangeError as e:\n",
    "        print(\"fetch data ended\")\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(object):\n",
    "    \"\"\"\n",
    "    Generator in GAN, used to generate \"fake\" images\n",
    "    Original paper: https://arxiv.org/pdf/1511.06434.pdf\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self._build_graph()\n",
    "    def _build_graph(self):\n",
    "        with tf.variable_scope(\"generator\") as scope:\n",
    "            print(\"### Print Generator Intermediate Parameter\")\n",
    "            self.prior = tf.placeholder(dtype=tf.float32, shape=(None, 100), name=\"prior_gen\")\n",
    "            self.is_training = tf.placeholder(dtype=tf.bool, shape = (), name=\"training_flag\")\n",
    "            prior_proj = tf.contrib.layers.fully_connected(inputs=self.prior, num_outputs=4*4*1024, \n",
    "                                                           activation_fn=None, scope=\"prior_projection\")\n",
    "            prior_proj = tf.contrib.layers.batch_norm(inputs=prior_proj, center=True, scale=True, activation_fn=tf.nn.relu, \n",
    "                                                  is_training= self.is_training, scope=\"bn0\")\n",
    "            conv0 = tf.reshape(prior_proj, (-1, 4, 4, 1024))\n",
    "            conv1 = tf.contrib.layers.convolution2d_transpose(inputs=conv0, num_outputs=512, activation_fn=None,\n",
    "                                                          kernel_size=(5,5), stride=(2,2), padding=\"SAME\",scope=\"deconv1\")\n",
    "            conv1 = tf.contrib.layers.batch_norm(inputs=conv1, center=True, scale=True, activation_fn=tf.nn.relu, \n",
    "                                             is_training= self.is_training, scope=\"bn1\")\n",
    "            print(conv1.shape)\n",
    "            conv2 = tf.contrib.layers.convolution2d_transpose(inputs=conv1, num_outputs=256, activation_fn=None,\n",
    "                                                          kernel_size=(5,5), stride=(2,2), padding=\"SAME\",scope=\"deconv2\")\n",
    "            conv2 = tf.contrib.layers.batch_norm(inputs=conv2, center=True, scale=True, activation_fn=tf.nn.relu, \n",
    "                                             is_training= self.is_training, scope=\"bn2\")\n",
    "            print(conv2.shape)\n",
    "            conv3 = tf.contrib.layers.convolution2d_transpose(inputs=conv2, num_outputs=128, activation_fn=None,\n",
    "                                                          kernel_size=(5,5), stride=(2,2), padding=\"SAME\",scope=\"deconv3\")\n",
    "            conv3 = tf.contrib.layers.batch_norm(inputs=conv3, center=True, scale=True, activation_fn=tf.nn.relu, \n",
    "                                             is_training= self.is_training, scope=\"bn3\")\n",
    "            print(conv3.shape)\n",
    "            conv4 = tf.contrib.layers.convolution2d_transpose(inputs=conv3, num_outputs=3, activation_fn=None,\n",
    "                                                          kernel_size=(5,5), stride=(2,2), padding=\"SAME\",scope=\"deconv4\")\n",
    "            self.gen_img = tf.nn.tanh(conv4)\n",
    "            self.gen_img_out = tf.cast(x=self.gen_img*128.0 + 128.0, dtype=tf.int32)\n",
    "            print(conv4.shape)\n",
    "            print(\"### End Print Generator Intermediate Parameter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.reset_default_graph()\n",
    "# g = Generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(object):\n",
    "    \"\"\"\n",
    "    Discriminator in GAN, used to distinguish \"fake\" and \"real\" images\n",
    "    \"\"\"\n",
    "    def __init__(self, img_gen):\n",
    "        self._build_graph(img_gen)\n",
    "    def _build_graph(self, image_gen):\n",
    "        self.real_img = tf.placeholder(tf.float32, (None, 64, 64, 3), name=\"real_image\")\n",
    "        real_img = (self.real_img - 128.0)/128.0\n",
    "        self.is_training = tf.placeholder(dtype=tf.bool, shape = (), name=\"training_flag\")\n",
    "        \n",
    "        self.real_judge = self._discrim(real_img)\n",
    "        #print(self.real_judge)\n",
    "        self.fake_judge = self._discrim(image_gen.gen_img, reuse = True)\n",
    "        #print(self.fake_judge)\n",
    "    def _discrim(self, input_img, reuse = None):\n",
    "        \"\"\"\n",
    "            This function will be called twice, \n",
    "            one for real images, and one for fake images.\n",
    "        \"\"\"\n",
    "        with tf.variable_scope(\"discriminator\") as scope:\n",
    "            if reuse: scope.reuse_variables()\n",
    "            print(\"### Print Discriminator Intermediate Parameter\")\n",
    "            \n",
    "            print(self.is_training)\n",
    "            conv1 = tf.contrib.layers.convolution2d(inputs=input_img, num_outputs=64, padding=\"SAME\",\n",
    "                                                    kernel_size=(3,3), stride=(1,1), activation_fn=None, scope = \"conv1\")\n",
    "            conv1 = tf.contrib.layers.batch_norm(inputs=conv1, center=True, scale=True, activation_fn=tf.nn.leaky_relu, \n",
    "                                             is_training= self.is_training, scope=\"bn1\")\n",
    "            print(conv1.shape)\n",
    "            conv2 = tf.contrib.layers.convolution2d(inputs=conv1, num_outputs=128, padding=\"SAME\",\n",
    "                                                    kernel_size=(3,3), stride=(2,2), activation_fn=None, scope = \"conv2\")\n",
    "            conv2 = tf.contrib.layers.batch_norm(inputs=conv2, center=True, scale=True, activation_fn=tf.nn.leaky_relu, \n",
    "                                             is_training= self.is_training, scope=\"bn2\")\n",
    "            print(conv2.shape)\n",
    "            ###\n",
    "            conv3 = tf.contrib.layers.convolution2d(inputs=conv2, num_outputs=128, padding=\"SAME\",\n",
    "                                                    kernel_size=(3,3), stride=(1,1), activation_fn=None, scope = \"conv3\")\n",
    "            conv3 = tf.contrib.layers.batch_norm(inputs=conv3, center=True, scale=True, activation_fn=tf.nn.leaky_relu, \n",
    "                                             is_training= self.is_training, scope=\"bn3\")\n",
    "            print(conv3.shape)\n",
    "            conv4 = tf.contrib.layers.convolution2d(inputs=conv3, num_outputs=256, padding=\"SAME\",\n",
    "                                                    kernel_size=(3,3), stride=(2,2), activation_fn=None, scope = \"conv4\")\n",
    "            conv4 = tf.contrib.layers.batch_norm(inputs=conv4, center=True, scale=True, activation_fn=tf.nn.leaky_relu, \n",
    "                                             is_training= self.is_training, scope=\"bn4\")\n",
    "            print(conv4.shape)\n",
    "            ###\n",
    "            conv5 = tf.contrib.layers.convolution2d(inputs=conv4, num_outputs=256, padding=\"SAME\",\n",
    "                                                    kernel_size=(3,3), stride=(1,1), activation_fn=None, scope = \"conv5\")\n",
    "            conv5 = tf.contrib.layers.batch_norm(inputs=conv5, center=True, scale=True, activation_fn=tf.nn.leaky_relu, \n",
    "                                             is_training= self.is_training, scope=\"bn5\")\n",
    "            print(conv5.shape)\n",
    "            conv6 = tf.contrib.layers.convolution2d(inputs=conv5, num_outputs=1024, padding=\"SAME\",\n",
    "                                                    kernel_size=(3,3), stride=(2,2), activation_fn=None, scope = \"conv6\")\n",
    "            conv6 = tf.contrib.layers.batch_norm(inputs=conv6, center=True, scale=True, activation_fn=tf.nn.leaky_relu, \n",
    "                                             is_training= self.is_training, scope=\"bn6\")\n",
    "            print(conv6.shape)\n",
    "            conv7 = tf.contrib.layers.convolution2d(inputs=conv6, num_outputs=1024, padding=\"SAME\",\n",
    "                                                    kernel_size=(3,3), stride=(1,1), activation_fn=None, scope = \"conv7\")\n",
    "            conv7 = tf.contrib.layers.batch_norm(inputs=conv7, center=True, scale=True, activation_fn=tf.nn.leaky_relu, \n",
    "                                             is_training= self.is_training, scope=\"bn7\")\n",
    "            print(conv7.shape)\n",
    "            conv8 = tf.contrib.layers.convolution2d(inputs=conv7, num_outputs=2048, padding=\"SAME\",\n",
    "                                                    kernel_size=(3,3), stride=(2,2), activation_fn=None, scope = \"conv8\")\n",
    "            conv8 = tf.contrib.layers.batch_norm(inputs=conv8, center=True, scale=True, activation_fn=tf.nn.leaky_relu, \n",
    "                                             is_training= self.is_training, scope=\"bn8\")\n",
    "            print(conv8.shape)\n",
    "            conv9 = tf.contrib.layers.convolution2d(inputs=conv8, num_outputs=102, padding=\"SAME\",\n",
    "                                                    kernel_size=(1,1), stride=(1,1), activation_fn=tf.nn.leaky_relu, scope=\"conv9\")\n",
    "            conv9 = tf.contrib.layers.avg_pool2d(inputs=conv9, kernel_size=(4,4), stride=(4,4), padding=\"SAME\", scope=\"avg_pool9\")\n",
    "            print(conv9.shape)\n",
    "            print(\"### End Print Discriminator Intermediate Parameter\")\n",
    "            ### no need to perform sigmoid\n",
    "            return tf.contrib.layers.fully_connected(inputs=tf.reshape(conv9,(-1, 102)), num_outputs=1, \n",
    "                                                     activation_fn=None, scope=\"output_projection\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.reset_default_graph()\n",
    "# g = Generator()\n",
    "# d = Discriminator(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='generator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='discriminator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GANModel(object):\n",
    "    def __init__(self, generator, discriminator, datasrc):\n",
    "        self.generator = generator\n",
    "        self.discriminator = discriminator\n",
    "        self.datasrc = datasrc\n",
    "        self.sess = None\n",
    "        self.saver = tf.train.Saver()\n",
    "    def train(self, model_path = None):\n",
    "        self.sess = tf.Session()\n",
    "        fake_result = self.discriminator.fake_judge\n",
    "        real_result = self.discriminator.real_judge\n",
    "        fake_rate = tf.reduce_mean(tf.cast(tf.nn.sigmoid(fake_result) > 0.5, tf.float32))\n",
    "        loss_g = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=fake_result , labels = tf.ones_like(fake_result)))\n",
    "        loss_d = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=real_result , labels = tf.ones_like(real_result)))\\\n",
    "               + tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=fake_result , labels = tf.zeros_like(fake_result)))\n",
    "        optim_g = tf.train.AdamOptimizer(tf.app.flags.FLAGS.learning_rate).minimize(loss_g, var_list = \\\n",
    "                                                           tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='generator'))\n",
    "        optim_d = tf.train.AdamOptimizer(tf.app.flags.FLAGS.learning_rate).minimize(loss_d, var_list = \\\n",
    "                                                           tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='discriminator'))\n",
    "        writer = tf.summary.FileWriter(\"./log\")\n",
    "        summary_g = tf.summary.scalar(name=\"generator_loss\", tensor=loss_g)\n",
    "        summary_d = tf.summary.scalar(name=\"discriminator_loss\", tensor=loss_d)\n",
    "        summary_fake_rate = tf.summary.scalar(name=\"fake_rate\", tensor=fake_rate)\n",
    "        \n",
    "        if model_path:\n",
    "            self.saver.restore(self.sess, model_path)\n",
    "            \n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "        self.sess.run(tf.local_variables_initializer())\n",
    "        \n",
    "        cnt_total = 0\n",
    "        coord = tf.train.Coordinator()\n",
    "        threads = tf.train.start_queue_runners(coord=coord, sess=self.sess)\n",
    "        try:\n",
    "            while True:\n",
    "                labels, imgs = self.sess.run(self.datasrc.get_data(), feed_dict = {})\n",
    "                # First train discriminator\n",
    "                # print(self.discriminator.is_training)\n",
    "                # print(self.generator.is_training)\n",
    "                loss_d_out, _, summary_d_out = self.sess.run([loss_d, optim_d, summary_d], \n",
    "                                                                 feed_dict = {\n",
    "                                                                      self.discriminator.real_img: imgs,\n",
    "                                                                      self.generator.prior: \\\n",
    "                                                                           np.random.randn(tf.app.flags.FLAGS.batch_size, 100)*1e-2,\n",
    "                                                                      self.discriminator.is_training: True,\n",
    "                                                                      self.generator.is_training: True\n",
    "                                                                })\n",
    "                # Then train generator\n",
    "                loss_g_out, _, summary_g_out = self.sess.run([loss_g, optim_g, summary_g], \n",
    "                                                                 feed_dict = {\n",
    "                                                                      self.generator.prior: \\\n",
    "                                                                           np.random.randn(tf.app.flags.FLAGS.batch_size, 100)*1e-2,\n",
    "                                                                      self.discriminator.is_training: True,\n",
    "                                                                      self.generator.is_training: True,\n",
    "                                                                })\n",
    "                # Then evaluate the fake ratio\n",
    "                fake_rate_out, summary_fake_rate_out = self.sess.run([fake_rate, summary_fake_rate],\n",
    "                                                                        feed_dict = {\n",
    "                                                                            self.generator.prior: \\\n",
    "                                                                                np.random.randn(tf.app.flags.FLAGS.batch_size, 100)*1e-2,\n",
    "                                                                            self.discriminator.is_training: False,\n",
    "                                                                            self.generator.is_training: False,\n",
    "                                                                        })\n",
    "                cnt_total += 1       \n",
    "                writer.add_summary(summary_d_out, cnt_total)\n",
    "                writer.add_summary(summary_g_out, cnt_total)\n",
    "                writer.add_summary(summary_fake_rate_out, cnt_total)\n",
    "                \n",
    "                print(\"In batch %3d, Dicriminator Loss %.3f, Generator Loss %.3f, Fake Ratio %.3f\\r\" \\\n",
    "                      %(cnt_total, loss_d_out, loss_g_out, fake_rate_out), end=\"\")\n",
    "                # Save every 100 batches\n",
    "                if cnt_total % 50 == 0:\n",
    "                    self.saver.save(self.sess, \"./log/model_%3d.ckpt\" %(cnt_total//50))\n",
    "                    \n",
    "        except tf.errors.OutOfRangeError as e:\n",
    "            print(\"fetch data ended\")\n",
    "        coord.request_stop()\n",
    "        coord.join(threads)\n",
    "        \n",
    "    def infer_gen(self, model_path = None, n_img = 1, prior=None):\n",
    "        \"\"\"\n",
    "            After the training, now we can use generator images!\n",
    "            n_img: number of images, if not given any prior\n",
    "            prior: given priors, if None, then random generate\n",
    "        \"\"\"\n",
    "        if not self.sess:\n",
    "            self.sess = tf.Session()\n",
    "        if not model_path:\n",
    "            print(\"Invalid model path!\")\n",
    "            sys.exit()\n",
    "        else:\n",
    "            self.saver.restore(self.sess, model_path)\n",
    "            \n",
    "        if not prior:\n",
    "            prior = np.random.randn(n_img, 100)* 1e-2\n",
    "            \n",
    "        imgs = self.sess.run(self.generator.gen_img_out, feed_dict = {self.generator.prior: prior, self.generator.is_training: False})\n",
    "        return imgs\n",
    "            \n",
    "    def infer_dis(self):\n",
    "        \"\"\"\n",
    "            In fact, discriminator can be used to predict,\n",
    "            but here we will not complete the code\n",
    "        \"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Print Generator Intermediate Parameter\n",
      "(?, 8, 8, 512)\n",
      "(?, 16, 16, 256)\n",
      "(?, 32, 32, 128)\n",
      "(?, 64, 64, 3)\n",
      "### End Print Generator Intermediate Parameter\n",
      "### Print Discriminator Intermediate Parameter\n",
      "Tensor(\"training_flag:0\", shape=(), dtype=bool)\n",
      "(?, 64, 64, 64)\n",
      "(?, 32, 32, 128)\n",
      "(?, 32, 32, 128)\n",
      "(?, 16, 16, 256)\n",
      "(?, 16, 16, 256)\n",
      "(?, 8, 8, 1024)\n",
      "(?, 8, 8, 1024)\n",
      "(?, 4, 4, 2048)\n",
      "(?, 1, 1, 102)\n",
      "### End Print Discriminator Intermediate Parameter\n",
      "### Print Discriminator Intermediate Parameter\n",
      "Tensor(\"training_flag:0\", shape=(), dtype=bool)\n",
      "(?, 64, 64, 64)\n",
      "(?, 32, 32, 128)\n",
      "(?, 32, 32, 128)\n",
      "(?, 16, 16, 256)\n",
      "(?, 16, 16, 256)\n",
      "(?, 8, 8, 1024)\n",
      "(?, 8, 8, 1024)\n",
      "(?, 4, 4, 2048)\n",
      "(?, 1, 1, 102)\n",
      "### End Print Discriminator Intermediate Parameter\n",
      "In batch  11, Dicriminator Loss 0.141, Generator Loss 3.950, Fake Ratio 0.000\r"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    tf.reset_default_graph()\n",
    "    dp = DataProcess(\"../dataset/102flowers/jpg/\")\n",
    "    g = Generator()\n",
    "    d = Discriminator(g)\n",
    "    gan = GANModel(generator=g, discriminator=d, datasrc=dp)\n",
    "    gan.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
